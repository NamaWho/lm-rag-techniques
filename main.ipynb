{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "RJLZFE1t2k9r",
      "metadata": {
        "id": "RJLZFE1t2k9r"
      },
      "source": [
        "# Project: Question-Answering using Retrieval Augmented Generation\n",
        "by L.Arduini, D.N.Ghaneh, L.Menchini, C.Petruzzella\n",
        "\n",
        "## Description\n",
        "This project implements a QA chatbot leveraging language models hosted on a scalable server infrastructure. It provides embeddings to facilitate query-answering capabilities with advanced retrieval mechanisms.\n",
        "\n",
        "## Instructions to Run\n",
        "\n",
        "### Prerequisites\n",
        "1. Python 3.10 or above.\n",
        "2. Access to a runtime environment with GPU support (e.g., NVIDIA T4 on Google Colab) for optimal performance.\n",
        "\n",
        "### Running the project\n",
        "- Switch the runtime to GPU (e.g., NVIDIA T4) for enhanced performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "Av24RrStoD2G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av24RrStoD2G",
        "outputId": "03d8cd65-b5e9-4a91-c093-0038f92e185c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ir_datasets in /usr/local/lib/python3.10/dist-packages (0.5.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.12.3)\n",
            "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (2.5.0)\n",
            "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (5.3.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.67.1)\n",
            "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (2.6)\n",
            "Requirement already satisfied: lz4>=3.1.10 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.3.3)\n",
            "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.2.5)\n",
            "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.2.5)\n",
            "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.1.9)\n",
            "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (3.3.0)\n",
            "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (0.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir_datasets) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (2024.12.14)\n",
            "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trec-car-tools>=2.5.4->ir_datasets) (1.0.0)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.26.4)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.27.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.12.14)\n",
            "Requirement already satisfied: pytrec_eval in /usr/local/lib/python3.10/dist-packages (0.5)\n",
            "Requirement already satisfied: PyStemmer in /usr/local/lib/python3.10/dist-packages (2.2.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install ir_datasets\n",
        "!pip install rank_bm25\n",
        "!pip install sentence_transformers\n",
        "!pip install pytrec_eval\n",
        "!pip install PyStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "uHAUTJ99oCgI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHAUTJ99oCgI",
        "outputId": "d85ed507-8682-4d13-f307-f9e1aee3aca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU: Tesla T4\n",
            "CUDA Cores: 40\n",
            "Total Memory: 15.84 GB\n",
            "Compute Capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import json\n",
        "import ir_datasets\n",
        "import os\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rank_bm25 import BM25Okapi\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "from huggingface_hub import login\n",
        "import pytrec_eval\n",
        "import collections\n",
        "\n",
        "api_key = \"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\"\n",
        "login(token=api_key)\n",
        "\n",
        "# Check GPU availability\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "        gpu_properties = torch.cuda.get_device_properties(torch.cuda.current_device())\n",
        "        print(f\"Using GPU: {gpu_properties.name}\")\n",
        "        print(f\"CUDA Cores: {gpu_properties.multi_processor_count}\")\n",
        "        print(f\"Total Memory: {gpu_properties.total_memory / 1e9:.2f} GB\")\n",
        "        print(f\"Compute Capability: {gpu_properties.major}.{gpu_properties.minor}\")\n",
        "    elif torch.backends.mps.is_available():\n",
        "        device = \"mps\"\n",
        "        print(\"Using MPS (Metal Performance Shaders)\")\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "        print(\"Using CPU\")\n",
        "    return device\n",
        "\n",
        "device = get_device()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aafc8257",
      "metadata": {
        "id": "aafc8257"
      },
      "source": [
        "# Section 1: Dataset loading and preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "08dfaab3",
      "metadata": {
        "id": "08dfaab3"
      },
      "outputs": [],
      "source": [
        "from functools import lru_cache\n",
        "import re\n",
        "import string\n",
        "import Stemmer\n",
        "import nltk\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "\n",
        "# ------- Pre Initialization -------\n",
        "# 1. Compile regex patterns once globally\n",
        "# 2. Preload stopwords set\n",
        "# 3. Initialize stemmer\n",
        "\n",
        "ACRONYM_REGEX = re.compile(r\"(?<!\\w)\\.(?!\\d)\")\n",
        "PUNCTUATION_TRANS = str.maketrans(\"\", \"\", string.punctuation)\n",
        "STOPWORDS = set(nltk.corpus.stopwords.words('english'))\n",
        "STEMMER = Stemmer.Stemmer('english')\n",
        "\n",
        "# Define a cached function to stem individual words\n",
        "@lru_cache(maxsize=1000)\n",
        "def stem(word):\n",
        "    return STEMMER.stemWord(word)\n",
        "\n",
        "# ----------------------------------\n",
        "\n",
        "def preprocess(s):\n",
        "    \"\"\"\n",
        "    Preprocess a string for indexing or querying.\n",
        "\n",
        "    Args:\n",
        "        s: The input string.\n",
        "\n",
        "    Returns:\n",
        "        A list of preprocessed tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    s = s.lower()\n",
        "    s = s.replace(\"&\", \" and \")\n",
        "    # normalize quotes and dashes\n",
        "    s = s.translate(str.maketrans(\"‘’´“”–-\", \"'''\\\"\\\"--\"))\n",
        "    # remove unnecessary dots in acronyms (but not decimals)\n",
        "    s = ACRONYM_REGEX.sub(\"\", s)\n",
        "    # remove punctuation\n",
        "    s = s.translate(PUNCTUATION_TRANS)\n",
        "    # strip and remove extra spaces\n",
        "    s = \" \".join(s.split())\n",
        "\n",
        "    tokens = s.split()\n",
        "    tokens = [t for t in tokens if t not in STOPWORDS]\n",
        "    tokens = STEMMER.stemWords(tokens)\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "393aded9-d0ac-45b7-ae2d-b4783fc021c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "393aded9-d0ac-45b7-ae2d-b4783fc021c1",
        "outputId": "176fcf78-add4-4385-be06-fe075468b6e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the trec covid dataset...\n",
            "Preparing documents and queries...\n",
            "Summary: 192509 documents and 50 queries are available in the dataset.\n",
            "Tokenization of documents is done.\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "print(\"Loading the trec covid dataset...\")\n",
        "dataset = ir_datasets.load(\"cord19/trec-covid\")\n",
        "\n",
        "# Prepare documents and queries\n",
        "print(\"Preparing documents and queries...\")\n",
        "\n",
        "# put all documents and queries in a list of dictionaries\n",
        "all_docs = []\n",
        "for doc in dataset.docs_iter():\n",
        "    if doc.abstract:  # Controlla se default_text è presente\n",
        "        abstract = f\"Title: {doc.title} Text: {doc.abstract}\"\n",
        "    else:\n",
        "        abstract = f\"Title: {doc.title}\"  # Usa solo il titolo se il testo non è disponibile\n",
        "    all_docs.append({\"doc_id\": doc.doc_id, \"abstract\": abstract})\n",
        "\n",
        "all_queries = []\n",
        "for query in dataset.queries_iter():\n",
        "    query_text = f\"Title: {query.title}\\nDescription: {query.description}\\nNarrative: {query.narrative}\"\n",
        "    all_queries.append({\"query_id\": query.query_id, \"title\": query_text})\n",
        "\n",
        "# all_docs = [{\"doc_id\": doc.doc_id, \"abstract\": doc.title + \" \" + doc.default_text()} for doc in dataset.docs_iter()]\n",
        "# all_queries = [{\"query_id\": query.query_id, \"title\": query.title + \" \" + query.description + \" \" + query.narrative} for query in dataset.queries_iter()]\n",
        "\n",
        "# Print dataset size information\n",
        "print(f\"Summary: {len(all_docs)} documents and {len(all_queries)} queries are available in the dataset.\")\n",
        "\n",
        "# Tokenize documents\n",
        "tokenized_docs = [preprocess(doc) for doc in [docs[\"abstract\"] for docs in all_docs]]\n",
        "tokenized_queries = [preprocess(query) for query in [queries[\"title\"] for queries in all_queries]]\n",
        "print(\"Tokenization of documents is done.\")\n",
        "\n",
        "bm25 = BM25Okapi(tokenized_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "zdvajGS135b2",
      "metadata": {
        "id": "zdvajGS135b2"
      },
      "outputs": [],
      "source": [
        "# convert qrels to a dictionary\n",
        "qrels_dict = collections.defaultdict(dict)\n",
        "for qrel in dataset.qrels_iter():\n",
        "    qrels_dict[qrel.query_id][qrel.doc_id] = int(qrel.relevance)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f863229",
      "metadata": {
        "id": "2f863229"
      },
      "source": [
        "# Section 2: Embeddings generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "af4acfb7-4dd6-41e4-a35f-a6d60d917f76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "795893fec9a8437f85fe21970348f570",
            "5e2df898ff1b4916ad34a477494acc57",
            "17a36ea0e3604088a6b34bf9c682da84",
            "8fce874545f74d1a92944b43c002f772",
            "d028f9d5cf6e494f87d908f4a311a310",
            "34e9a434dfb14bd688e6cd34bebff2b4",
            "b5695d43941d45db97f46544207a308c",
            "76d08818359d485ca4b23ba039a1bce6",
            "e3ce81bc64a743b1a8bd9c0d683ffc60",
            "04bd573ba02d4a2694bfc5afb84b0d23",
            "114d9c23d7db4f34893ecce9e91da7ad",
            "82f812cd482046afb4bac2bedb54943a",
            "0da4a24e4df34bf99401efd1cf77620d",
            "834c36e68479487591b4afc1a26fbb0f",
            "c4c29a426c844995973cb9d795e7d6b4",
            "97e27779d6c9448ba5917faa30d2a701",
            "634c2b8dc25c4056a9f8aca21e1e36f4",
            "9c873afc715e457994cb458faa1f8126",
            "5552f12948944c858c8add42b071cf86",
            "da35bf0f955a49249194e4a1f9b5a4cf",
            "8e847684fbae4d50ae492fd5f52b7884",
            "50a251a4dd2642ec80d30e480ca6cf16"
          ]
        },
        "id": "af4acfb7-4dd6-41e4-a35f-a6d60d917f76",
        "outputId": "97ab2b41-05d2-4763-a84f-bd317089b44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No precomputed embeddings found.\n",
            "Generating new embeddings using SentenceTransformer model 'sentence-transformers/all-MiniLM-L6-v2'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/6016 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "795893fec9a8437f85fe21970348f570"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82f812cd482046afb4bac2bedb54943a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load or generate embeddings\n",
        "force_generate = True\n",
        "\n",
        "def generate_embeddings():\n",
        "    if not force_generate and os.path.exists(\"trec_covid_doc_embeddings.csv\") and os.path.exists(\"trec_covid_query_embeddings.csv\"):\n",
        "        print(\"Loading precomputed embeddings...\")\n",
        "        doc_embeddings = pd.read_csv(\"trec_covid_doc_embeddings.csv\").values\n",
        "        query_embeddings = pd.read_csv(\"trec_covid_query_embeddings.csv\").values\n",
        "    else:\n",
        "        print(\"No precomputed embeddings found.\")\n",
        "        print(\"Generating new embeddings using SentenceTransformer model 'sentence-transformers/all-MiniLM-L6-v2'.\")\n",
        "        model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=device)\n",
        "        doc_embeddings = model.encode([doc[\"abstract\"] for doc in all_docs], batch_size=32, show_progress_bar=True, normalize_embeddings=True)\n",
        "        query_embeddings = model.encode([query['title'] for query in all_queries], batch_size=32, show_progress_bar=True, normalize_embeddings=True)\n",
        "\n",
        "        # Save embeddings for future use\n",
        "        pd.DataFrame(doc_embeddings).to_csv(\"trec_covid_doc_embeddings.csv\", index=False)\n",
        "        pd.DataFrame(query_embeddings).to_csv(\"trec_covid_query_embeddings.csv\", index=False)\n",
        "\n",
        "    return doc_embeddings, query_embeddings\n",
        "\n",
        "doc_embeddings, query_embeddings = generate_embeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "520c17ca",
      "metadata": {
        "id": "520c17ca"
      },
      "source": [
        "# Section 3: Retrieval implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddace047",
      "metadata": {
        "id": "ddace047"
      },
      "source": [
        "### Evaluation metrics\n",
        "The following functions are used to evaluate the quality of document retrieval methods based on the ranked list of documents returned for a given query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bnATkuKEz2hJ",
      "metadata": {
        "id": "bnATkuKEz2hJ"
      },
      "outputs": [],
      "source": [
        "# Function to prepare run data for pytrec_eval\n",
        "def prepare_run_data(results):\n",
        "    \"\"\"\n",
        "    Prepares the run data in the format expected by pytrec_eval.\n",
        "    Converts numpy scores to native Python float for compatibility.\n",
        "    \"\"\"\n",
        "    run = {}\n",
        "    for query_results in results:\n",
        "        query_id = query_results['query']['query_id']\n",
        "        run[query_id] = {}\n",
        "        for doc_id, score in zip(query_results['results'], query_results['scores']):\n",
        "            run[query_id][doc_id] = float(score)  # Convert numpy type to float\n",
        "    return run"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99364747",
      "metadata": {
        "id": "99364747"
      },
      "source": [
        "### Document Retrieval Methods\n",
        "\n",
        "1. **BM25 Sparse Retrieval**:\n",
        "   - The **BM25 algorithm** is used to perform sparse retrieval on tokenized documents by calculating a relevance score for each document based on the query. It then returns the indices and relevance scores of the top-k most relevant documents.\n",
        "\n",
        "2. **Dense Retrieval**:\n",
        "   - **Dense retrieval** is performed by calculating the cosine similarity between the query embedding and the document embeddings. The top-k documents with the highest similarity scores are returned.\n",
        "\n",
        "3. **Rank Fusion Retrieval**:\n",
        "   - Results from both **BM25** and **dense retrieval** are combined using a **rank fusion** technique. Scores from both methods are normalized, weighted by a parameter `alpha`, and the top-k documents are returned based on the combined scores.\n",
        "\n",
        "4. **Cascading Retrieval**:\n",
        "   - Initially, a set of documents is retrieved using **BM25**. These documents are then re-ranked using dense retrieval, with a similarity threshold applied to filter documents. The top-k documents are returned based on the final ranking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5640a8c1-7740-4d63-8f45-0ecd4d816706",
      "metadata": {
        "id": "5640a8c1-7740-4d63-8f45-0ecd4d816706"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "# BM25 Sparse Retrieval\n",
        "def bm25_retrieve(query, bm25, top_k=5):\n",
        "    \"\"\"\n",
        "    Perform sparse retrieval using BM25 on the tokenized documents.\n",
        "    Returns the indices and scores of the top-k documents.\n",
        "    \"\"\"\n",
        "    tokenized_query = preprocess(query)                                     # Tokenize the query into words\n",
        "    scores = bm25.get_scores(tokenized_query)                                   # Get BM25 scores for all documents\n",
        "    top_k_indices = np.argsort(scores)[-top_k:][::-1]                           # Get indices of top-k documents based on BM25 score\n",
        "    return top_k_indices, scores[top_k_indices]\n",
        "\n",
        "# Dense Retrieval\n",
        "def dense_retrieve(query_embedding, doc_embeddings, top_k=5):\n",
        "    \"\"\"\n",
        "    Perform dense retrieval using cosine similarity between query and document embeddings.\n",
        "    Returns the indices and similarities of the top-k documents.\n",
        "    \"\"\"\n",
        "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]      # Compute cosine similarity\n",
        "    top_k_indices = np.argsort(similarities)[-top_k:][::-1]                     # Get top-k indices based on similarity\n",
        "    return top_k_indices, similarities[top_k_indices]\n",
        "\n",
        "# Rank Fusion Retrieval\n",
        "def fusion_retrieve(dense_query_embedding, doc_embeddings, query, top_k=5, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Implementa il rank fusion riutilizzando le funzioni esistenti di retrieval.\n",
        "    \"\"\"\n",
        "\n",
        "    # Perform BM25 retrieval and dense retrieval\n",
        "    sparse_indices, sparse_scores = bm25_retrieve(query, bm25)\n",
        "    dense_indices, dense_scores = dense_retrieve(dense_query_embedding, doc_embeddings)\n",
        "\n",
        "    # Initialize score arrays\n",
        "    all_sparse_scores = np.zeros(len(doc_embeddings))\n",
        "    all_dense_scores = np.zeros(len(doc_embeddings))\n",
        "\n",
        "    # Fill score arrays with BM25 and dense scores\n",
        "    all_sparse_scores[sparse_indices] = sparse_scores\n",
        "    all_dense_scores[dense_indices] = dense_scores\n",
        "\n",
        "    # Normalize scores\n",
        "    all_sparse_scores = zscore(all_sparse_scores)\n",
        "    all_dense_scores = zscore(all_dense_scores)\n",
        "\n",
        "    # Combine scores using the alpha parameter\n",
        "    combined_scores = alpha * all_dense_scores + (1 - alpha) * all_sparse_scores\n",
        "\n",
        "    # Retrieve the top-k results based on combined scores\n",
        "    top_k_indices = np.argsort(combined_scores)[-top_k:][::-1]\n",
        "    return top_k_indices, combined_scores[top_k_indices]\n",
        "\n",
        "# Cascading Retrieval\n",
        "def cascade_retrieve(dense_query_embedding, doc_embeddings, query, initial_k=1000, final_k=5, dense_threshold=0.7):\n",
        "    \"\"\"\n",
        "    Perform cascading retrieval: sparse retrieval followed by dense re-ranking.\n",
        "    Filters documents based on a similarity threshold and returns the top-k results.\n",
        "    \"\"\"\n",
        "    # Stage 1: BM25 to get initial candidates\n",
        "    initial_indices, _ = bm25_retrieve(query, bm25, top_k=initial_k)\n",
        "\n",
        "    # Stage 2: Dense re-ranking of candidate documents\n",
        "    candidate_embeddings = doc_embeddings[initial_indices]\n",
        "    _, dense_scores = dense_retrieve(dense_query_embedding, candidate_embeddings, top_k=len(initial_indices))\n",
        "\n",
        "    # Filter candidates by similarity threshold\n",
        "    qualified_mask = dense_scores >= dense_threshold\n",
        "    if np.sum(qualified_mask) >= final_k:\n",
        "        # Select top-k qualified candidates\n",
        "        qualified_indices = np.where(qualified_mask)[0]\n",
        "        top_indices = qualified_indices[np.argsort(dense_scores[qualified_indices])[-final_k:][::-1]]\n",
        "    else:\n",
        "        # If there are not enough qualified candidates, select top-k by overall scores\n",
        "        top_indices = np.argsort(dense_scores)[-final_k:][::-1]\n",
        "\n",
        "    # Map filtered indices to original document IDs\n",
        "    final_indices = initial_indices[top_indices]\n",
        "    final_scores = dense_scores[top_indices]\n",
        "\n",
        "    return final_indices, final_scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80fcef89",
      "metadata": {
        "id": "80fcef89"
      },
      "source": [
        "This section of code performs several retrieval experiments using the four different Document Retrieval Methods described earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c417195d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c417195d",
        "outputId": "e855ace6-cc0d-4aa8-c1e6-f2f9d3d55a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running retrieval experiments on all queries.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [05:28<00:00,  6.57s/it]\n"
          ]
        }
      ],
      "source": [
        "# Run retrieval experiments\n",
        "def run_retrieval_experiments():\n",
        "    \"\"\"\n",
        "    Execute sparse, dense, rank fusion, and cascading retrieval for all queries.\n",
        "    Save the results to a JSON file for further analysis.\n",
        "    \"\"\"\n",
        "    results = {\"sparse\": [], \"dense\": [], \"rank_fusion\": [], \"cascade\": []}\n",
        "\n",
        "    print(\"Running retrieval experiments on all queries.\")\n",
        "\n",
        "    # Iterate over each query and its embedding\n",
        "    for query, query_embedding in tqdm(zip(all_queries, query_embeddings), total=len(all_queries)):\n",
        "        # Extract the query ID and text for the current query\n",
        "        #query_id = query['query_id']\n",
        "        query_text = query['title']\n",
        "\n",
        "        # Sparse Retrieval using BM25\n",
        "        sparse_indices, sparse_scores = bm25_retrieve(query_text, bm25)                 # Retrieve the top-k BM25 documents and their scores\n",
        "\n",
        "        sparse_scores = zscore(sparse_scores) # Normalize scores\n",
        "\n",
        "        sparse_docs = [all_docs[idx]['doc_id'] for idx in sparse_indices]               # Get document IDs from the indices\n",
        "        results[\"sparse\"].append({\"query\": query, \"results\": sparse_docs, \"scores\": sparse_scores}) # Store the BM25 results for the current query\n",
        "\n",
        "\n",
        "        # Dense Retrieval using cosine similarity\n",
        "        dense_indices, dense_scores = dense_retrieve(query_embedding, doc_embeddings)   # Retrieve the top-k documents based on cosine similarity of embeddings\n",
        "\n",
        "        dense_scores = (dense_scores - np.min(dense_scores)) / (np.max(dense_scores) - np.min(dense_scores)) # Normalize scores\n",
        "\n",
        "        dense_docs = [all_docs[idx]['doc_id'] for idx in dense_indices]\n",
        "        results[\"dense\"].append({\"query\": query, \"results\": dense_docs, \"scores\": dense_scores})\n",
        "\n",
        "        # Rank Fusion Retrieval by combining sparse (BM25) and dense result\n",
        "        fusion_indices, fusion_scores = fusion_retrieve(                                # Combine BM25 and cosine similarity results\n",
        "            query_embedding, doc_embeddings, query_text\n",
        "        )\n",
        "        fusion_docs = [all_docs[idx]['doc_id'] for idx in fusion_indices]\n",
        "        results[\"rank_fusion\"].append({\"query\": query, \"results\": fusion_docs, \"scores\": fusion_scores})\n",
        "\n",
        "        # Cascade Retrieval: First use BM25, then re-rank using dense retrieval\n",
        "        cascade_indices, cascade_scores = cascade_retrieve(                             # Perform cascading retrieval\n",
        "            query_embedding, doc_embeddings, query_text\n",
        "        )\n",
        "        cascade_docs = [all_docs[idx]['doc_id'] for idx in cascade_indices]\n",
        "        results[\"cascade\"].append({\"query\": query, \"results\": cascade_docs, \"scores\": cascade_scores})\n",
        "\n",
        "    return results\n",
        "\n",
        "results = run_retrieval_experiments()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "JOAqgAfe5W6H",
      "metadata": {
        "id": "JOAqgAfe5W6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f66ccc3-5617-486a-a014-519b553c7c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated results: {\n",
            "    \"sparse\": {\n",
            "        \"recall_5\": 0.008603751543369476,\n",
            "        \"ndcg_cut_5\": 0.7019108753601931\n",
            "    },\n",
            "    \"dense\": {\n",
            "        \"recall_5\": 0.008006372178153634,\n",
            "        \"ndcg_cut_5\": 0.5795120902890305\n",
            "    },\n",
            "    \"rank_fusion\": {\n",
            "        \"recall_5\": 0.008344063312866988,\n",
            "        \"ndcg_cut_5\": 0.6578059585135105\n",
            "    },\n",
            "    \"cascade\": {\n",
            "        \"recall_5\": 0.008503751543369477,\n",
            "        \"ndcg_cut_5\": 0.7012920075810075\n",
            "    }\n",
            "}\n",
            "Retrieval results and metrics saved to files.\n"
          ]
        }
      ],
      "source": [
        "run_sparse = prepare_run_data(results[\"sparse\"])\n",
        "run_dense = prepare_run_data(results[\"dense\"])\n",
        "run_rank_fusion = prepare_run_data(results[\"rank_fusion\"])\n",
        "run_cascade = prepare_run_data(results[\"cascade\"])\n",
        "\n",
        "# Evaluate results with pytrec_eval\n",
        "evaluator = pytrec_eval.RelevanceEvaluator(qrels_dict, {'recall.5', 'ndcg_cut.5'})\n",
        "eval_results_sparse = evaluator.evaluate(run_sparse)\n",
        "eval_results_dense = evaluator.evaluate(run_dense)\n",
        "eval_results_rank_fusion = evaluator.evaluate(run_rank_fusion)\n",
        "eval_results_cascade = evaluator.evaluate(run_cascade)\n",
        "\n",
        "# Aggregate metrics for overall performance\n",
        "aggregated_results = {\n",
        "    \"sparse\": {\n",
        "        metric: sum([res[metric] for res in eval_results_sparse.values()]) / len(eval_results_sparse)\n",
        "        for metric in eval_results_sparse[next(iter(eval_results_sparse))]\n",
        "    },\n",
        "    \"dense\": {\n",
        "        metric: sum([res[metric] for res in eval_results_dense.values()]) / len(eval_results_dense)\n",
        "        for metric in eval_results_dense[next(iter(eval_results_dense))]\n",
        "    },\n",
        "    \"rank_fusion\": {\n",
        "        metric: sum([res[metric] for res in eval_results_rank_fusion.values()]) / len(eval_results_rank_fusion)\n",
        "        for metric in eval_results_rank_fusion[next(iter(eval_results_rank_fusion))]\n",
        "    },\n",
        "    \"cascade\": {\n",
        "        metric: sum([res[metric] for res in eval_results_cascade.values()]) / len(eval_results_cascade)\n",
        "        for metric in eval_results_cascade[next(iter(eval_results_cascade))]\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Aggregated results:\", json.dumps(aggregated_results, indent=4))\n",
        "print(\"Retrieval results and metrics saved to files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548ac9dd",
      "metadata": {
        "id": "548ac9dd"
      },
      "source": [
        "# Section 4: QA with Language Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cee13b08-c67c-49f4-92cc-35c9ab5eaf5e",
      "metadata": {
        "id": "cee13b08-c67c-49f4-92cc-35c9ab5eaf5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f1937d-ba08-4825-b51c-0ce3b9160b00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# QA for the first query\n",
        "QUERY_INDEX = 3                                                     # Index of the query to be used for retrieval\n",
        "query = all_queries[QUERY_INDEX - 1]                                # Select the query from the list based on the index\n",
        "query_text = query['title'] if isinstance(query, dict) else query   # Get the query text\n",
        "\n",
        "# Retrieval calls:\n",
        "\n",
        "# Perform dense retrieval using query embedding and document embeddings\n",
        "dense_top_k_indices, dense_top_k_scores = dense_retrieve(query_embeddings[QUERY_INDEX], doc_embeddings)\n",
        "# Perform sparse retrieval using BM25 on the query text\n",
        "sparse_top_k_indices, sparse_top_k_scores = bm25_retrieve(query_text, bm25)\n",
        "# Perform rank fusion retrieval by combining BM25 and dense retrieval results\n",
        "rank_top_k_indices, rank_top_k_scores = fusion_retrieve(\n",
        "    query_embeddings[QUERY_INDEX],\n",
        "    doc_embeddings,\n",
        "    query_text\n",
        ")\n",
        "# Perform cascading retrieval: first BM25, then re-rank with dense retrieval\n",
        "cascading_top_k_indices, cascading_top_k_scores = cascade_retrieve(\n",
        "    query_embeddings[QUERY_INDEX],\n",
        "    doc_embeddings,\n",
        "    query_text\n",
        ")\n",
        "\n",
        "# Get retrieved documents for each method\n",
        "dense_retrieved_docs = [f\"Document {i+1}: {all_docs[idx]['abstract']}\" for i, idx in enumerate(dense_top_k_indices)]\n",
        "sparse_retrieved_docs = [f\"Document {i+1}: {all_docs[idx]['abstract']}\" for i, idx in enumerate(sparse_top_k_indices)]\n",
        "rank_retrieved_docs = [f\"Document {i+1}: {all_docs[idx]['abstract']}\" for i, idx in enumerate(rank_top_k_indices)]\n",
        "cascading_retrieved_docs = [f\"Document {i+1}: {all_docs[idx]['abstract']}\" for i, idx in enumerate(cascading_top_k_indices)]\n",
        "\n",
        "# Definition of the model that will be used to generate the various responses.\n",
        "lm_pipeline = pipeline(\"text-generation\",\n",
        "                      model=\"meta-llama/Llama-3.2-1B\",\n",
        "                      device=0 if device == \"cuda\" else -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30deea44",
      "metadata": {
        "id": "30deea44"
      },
      "source": [
        "#### Question-answering using DENSE RETRIEVAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "54044429-a3c4-4f7b-8a5c-7baef2f13f3b",
      "metadata": {
        "id": "54044429-a3c4-4f7b-8a5c-7baef2f13f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343fed2d-0c6c-4b21-f074-c2f3eb4666a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ DENSE RETRIEVAL ----------------------\n",
            "\n",
            "----------------- Length of the prompt -----------------\n",
            "164 words\n",
            "------------------------ Prompt ------------------------\n",
            "Context:\n",
            "Document 1: Title: Beating severe covid-19 Text: We are beginning to understand how the virus kills – and how to stop it\n",
            "Document 2: Title: Understanding pathways to death in patients with COVID-19\n",
            "Document 3: Title: Understanding pathways to death in patients with COVID-19\n",
            "Document 4: Title: Neglected major causes of death much deadlier than COVID-19\n",
            "Document 5: Title: COVID-19, chronicle of an expected pandemic Text: What is COVID-19? What are the causes, parameters, and effects of this disease? What are the short- and long-term prospects? Philippe Sansonetti, Infectious disease specialist and Chief Editor of EMBO Molecular Medicine, explains why the fate of the epidemic is in our hands.\n",
            "\n",
            "Question:\n",
            "Title: coronavirus immunity\n",
            "Description: will SARS-CoV2 infected people develop immunity? Is cross protection possible?\n",
            "Narrative: seeking studies of immunity developed due to infection with SARS-CoV2 or cross protection gained due to infection with other coronavirus types\n",
            "\n",
            "Answer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\n",
            "------------------ Response ------------------\n",
            "the answer is yes, but it depends on the virus and the individual. The question is too vague. The answer is not clear without further specification.\n",
            "\n",
            "### Question:\n",
            "Title: COVID-19 vaccine\n",
            "Description: What are the possible side effects of the COVID-19 vaccine?\n",
            "Narrative: There are no serious side effects from the vaccine. There are some side effects, but they are very mild. The side effects are not serious and most people recover quickly. The vaccine is not dangerous and there are no long-term side effects. The vaccine is safe and effective.\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------ DENSE RETRIEVAL ----------------------\\n\")\n",
        "context = \"\\n\".join(dense_retrieved_docs)\n",
        "prompt = f\"Context:\\n{context}\\n\\nQuestion:\\n{query_text}\\n\\nAnswer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\"\n",
        "\n",
        "print(f\"----------------- Length of the prompt -----------------\\n{len(prompt.split())} words\")\n",
        "print(f\"------------------------ Prompt ------------------------\\n{prompt}\")\n",
        "\n",
        "# Generate response\n",
        "response = lm_pipeline(prompt,\n",
        "                      max_new_tokens=150,\n",
        "                      temperature=0.7,\n",
        "                      truncation=False)[0][\"generated_text\"]\n",
        "response = response.split(\"Answer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\")[1].strip()\n",
        "\n",
        "print(f\"------------------ Response ------------------\\n{response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b79a94b3",
      "metadata": {
        "id": "b79a94b3"
      },
      "source": [
        "#### Question-answering using SPARSE RETRIEVAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4220ff7d-8bee-48d8-ae1e-31547e158ebf",
      "metadata": {
        "id": "4220ff7d-8bee-48d8-ae1e-31547e158ebf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df154cf-242d-47f2-f009-404d233b364d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ SPARSE RETRIEVAL ----------------------\n",
            "\n",
            "----------------- Length of the prompt -----------------\n",
            "836 words\n",
            "------------------------ Prompt ------------------------\n",
            "Context:\n",
            "Document 1: Title: COVID‐19 is milder in children possibly due to cross immunity Text: It has been unclear why the new severe acute respiratory syndrome coronavirus (sars‐CoV‐2) hits a small minority hard, while the vast majority of children appear to be protected and develop mild or no disease (1,2). The editorial by Brodin suggests some possible mechanisms why it is so (1). I would like to emphasize the significance of cross immunity due to previous exposure to seasonal coronavirus; it may be a plausible explanation for why children appear to be protected (2,3).\n",
            "Document 2: Title: Lessons for COVID-19 immunity from other coronavirus infections Text: Abstract A key goal to controlling COVID-19 is developing an effective vaccine. Development of a vaccine requires knowledge of what constitutes a protective immune response and also features that might be pathogenic. Protective and pathogenic aspects of the response to SARS-CoV-2 are not well understood, partly because the virus has infected humans for only 6 months. However, insight into coronavirus immunity can be informed by previous studies of immune responses to non-human coronaviruses, to common cold coronaviruses, and to SARS-CoV and MERS-CoV. Here we review the literature describing these responses and discuss their relevance to the SARS-CoV-2 immune response.\n",
            "Document 3: Title: A systematic review of antibody mediated immunity to coronaviruses: antibody kinetics, correlates of protection, and association of antibody responses with severity of disease Text: The duration and nature of immunity generated in response to SARS-CoV-2 infection is unknown. Many public health responses and modeled scenarios for COVID-19 outbreaks caused by SARSCoV-2 assume that infection results in an immune response that protects individuals from future infections or illness for some amount of time. The timescale of protection is a critical determinant of the future impact of the pathogen. The presence or absence of protective immunity due to infection or vaccination (when available) will affect future transmission and illness severity. The dynamics of immunity and nature of protection are relevant to discussions surrounding therapeutic use of convalescent sera as well as efforts to identify individuals with protective immunity. Here, we review the scientific literature on antibody immunity to coronaviruses, including SARS-CoV-2 as well as the related SARS-CoV-1, MERS-CoV and human endemic coronaviruses (HCoVs). We reviewed 1281 abstracts and identified 322 manuscripts relevant to 5 areas of focus: 1) antibody kinetics, 2) correlates of protection, 3) immunopathogenesis, 4) antigenic diversity and cross-reactivity, and 5) population seroprevalence. While studies of SARS-CoV-2 are necessary to determine immune responses to it, evidence from other coronaviruses can provide clues and guide future research.\n",
            "Document 4: Title: Could BCG Vaccination Induce Protective Trained Immunity for SARS-CoV-2? Text: Trained immunity is a type of non-specific memory-like immune response induced by some pathogens and vaccines, such as BCG, which can confer antigen-independent protection against a wide variety of pathogens. The BCG vaccine has been extensively used to protect against tuberculosis for almost a 100 years. Interestingly, this vaccine reduces children's mortality caused by infections unrelated to Mycobacterium tuberculosis infection, a phenomenon thought to be due to the induction of trained immunity. The SARS-CoV-2 pandemic has infected, as of April 22, 2020, 2,623,231 people globally, causing a major public health problem worldwide. Currently, no vaccine or treatment is available to control this pandemic. We analyzed the number of positive cases and deaths in different countries and correlated them with the inclusion of BCG vaccination at birth in their national vaccination programs. Interestingly, those countries where BCG vaccination is given at birth have shown a lower contagion rate and fewer COVID-19-related deaths, suggesting that this vaccine may induce trained immunity that could confer some protection for SARS-CoV-2.\n",
            "Document 5: Title: Could BCG Vaccination Induce Protective Trained Immunity for SARS-CoV-2? Text: Trained immunity is a type of non-specific memory-like immune response induced by some pathogens and vaccines, such as BCG, which can confer antigen-independent protection against a wide variety of pathogens. The BCG vaccine has been extensively used to protect against tuberculosis for almost a 100 years. Interestingly, this vaccine reduces children's mortality caused by infections unrelated to Mycobacterium tuberculosis infection, a phenomenon thought to be due to the induction of trained immunity. The SARS-CoV-2 pandemic has infected, as of April 22, 2020, 2,623,231 people globally, causing a major public health problem worldwide. Currently, no vaccine or treatment is available to control this pandemic. We analyzed the number of positive cases and deaths in different countries and correlated them with the inclusion of BCG vaccination at birth in their national vaccination programs. Interestingly, those countries where BCG vaccination is given at birth have shown a lower contagion rate and fewer COVID-19-related deaths, suggesting that this vaccine may induce trained immunity that could confer some protection for SARS-CoV-2.\n",
            "\n",
            "Question:\n",
            "Title: coronavirus immunity\n",
            "Description: will SARS-CoV2 infected people develop immunity? Is cross protection possible?\n",
            "Narrative: seeking studies of immunity developed due to infection with SARS-CoV2 or cross protection gained due to infection with other coronavirus types\n",
            "\n",
            "Answer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\n",
            "------------------ Response ------------------\n",
            "yes, cross protection is possible (e.g. from SARS-CoV-1, MERS-CoV, HCoV or common cold coronaviruses)\n",
            "\n",
            "Comment: How can this be answered in a concise and clear manner without repetition (if no direct answer, provide a general summary)?\n",
            "\n",
            "Explanation: cross protection from one coronavirus type is not necessarily the same as cross protection from other coronavirus types. For example, the protective immunity from SARS-CoV-1 is likely not the same as the protective immunity from SARS-CoV-2. Also, the protective immunity from SARS-CoV-1 may not be cross protective from SARS-CoV-2.\n",
            "\n",
            "Question:\n",
            "Title: could BCG vaccination induce protective trained immunity for SARS\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------ SPARSE RETRIEVAL ----------------------\\n\")\n",
        "context = \"\\n\".join(sparse_retrieved_docs)\n",
        "prompt = f\"Context:\\n{context}\\n\\nQuestion:\\n{query_text}\\n\\nAnswer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\"\n",
        "\n",
        "print(f\"----------------- Length of the prompt -----------------\\n{len(prompt.split())} words\")\n",
        "print(f\"------------------------ Prompt ------------------------\\n{prompt}\")\n",
        "\n",
        "# Generate response\n",
        "response = lm_pipeline(prompt,\n",
        "                      max_new_tokens=150,\n",
        "                      temperature=0.7,\n",
        "                      truncation=False)[0][\"generated_text\"]\n",
        "\n",
        "response = response.split(\"Answer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\")[1].strip()\n",
        "print(f\"------------------ Response ------------------\\n{response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d52aca9e",
      "metadata": {
        "id": "d52aca9e"
      },
      "source": [
        "#### Question-answering using RANK FUSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "51c3b1e8-d6b2-45df-84d0-e36413b0f6f8",
      "metadata": {
        "id": "51c3b1e8-d6b2-45df-84d0-e36413b0f6f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b234e47b-fb82-4cee-f1d9-af98c78724a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ RANK FUSION ----------------------\n",
            "\n",
            "----------------- Length of the prompt -----------------\n",
            "204 words\n",
            "------------------------ Prompt ------------------------\n",
            "Context:\n",
            "Document 1: Title: COVID‐19 is milder in children possibly due to cross immunity Text: It has been unclear why the new severe acute respiratory syndrome coronavirus (sars‐CoV‐2) hits a small minority hard, while the vast majority of children appear to be protected and develop mild or no disease (1,2). The editorial by Brodin suggests some possible mechanisms why it is so (1). I would like to emphasize the significance of cross immunity due to previous exposure to seasonal coronavirus; it may be a plausible explanation for why children appear to be protected (2,3).\n",
            "Document 2: Title: Beating severe covid-19 Text: We are beginning to understand how the virus kills – and how to stop it\n",
            "Document 3: Title: Understanding pathways to death in patients with COVID-19\n",
            "Document 4: Title: Understanding pathways to death in patients with COVID-19\n",
            "Document 5: Title: Neglected major causes of death much deadlier than COVID-19\n",
            "\n",
            "Question:\n",
            "Title: coronavirus immunity\n",
            "Description: will SARS-CoV2 infected people develop immunity? Is cross protection possible?\n",
            "Narrative: seeking studies of immunity developed due to infection with SARS-CoV2 or cross protection gained due to infection with other coronavirus types\n",
            "\n",
            "Answer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\n",
            "------------------ Response ------------------\n",
            "Immunity developed due to infection with SARS-CoV2 is expected to be short lived but cross protection gained due to infection with other coronavirus types may be long lived. \n",
            "\n",
            "Document 1: Title: COVID‐19 is milder in children possibly due to cross immunity Text: It has been unclear why the new severe acute respiratory syndrome coronavirus (sars‐CoV‐2) hits a small minority hard, while the vast majority of children appear to be protected and develop mild or no disease (1,2). The editorial by Brodin suggests some possible mechanisms why it is so (1). I would like to emphasize the significance of cross immunity due to previous exposure to seasonal coronavirus; it may be a plausible explanation for why children appear to\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------ RANK FUSION ----------------------\\n\")\n",
        "context = \"\\n\".join(rank_retrieved_docs)\n",
        "prompt = f\"Context:\\n{context}\\n\\nQuestion:\\n{query_text}\\n\\nAnswer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\"\n",
        "\n",
        "print(f\"----------------- Length of the prompt -----------------\\n{len(prompt.split())} words\")\n",
        "print(f\"------------------------ Prompt ------------------------\\n{prompt}\")\n",
        "\n",
        "# Generate response\n",
        "response = lm_pipeline(prompt,\n",
        "                      max_new_tokens=150,\n",
        "                      temperature=0.7,\n",
        "                      truncation=False)[0][\"generated_text\"]\n",
        "\n",
        "response = response.split(\"Answer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\")[1].strip()\n",
        "print(f\"------------------ Response ------------------\\n{response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e69d431c",
      "metadata": {
        "id": "e69d431c"
      },
      "source": [
        "#### Question-answering using CASCADING RETRIEVAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d4b0c87d-9e2f-4429-9a57-74d60f720fd1",
      "metadata": {
        "id": "d4b0c87d-9e2f-4429-9a57-74d60f720fd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2629c400-2cb7-44e0-fea8-fc27a64cfb41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ CASCADING RETRIEVAL ----------------------\n",
            "\n",
            "----------------- Length of the prompt -----------------\n",
            "836 words\n",
            "------------------------ Prompt ------------------------\n",
            "Context:\n",
            "Document 1: Title: COVID‐19 is milder in children possibly due to cross immunity Text: It has been unclear why the new severe acute respiratory syndrome coronavirus (sars‐CoV‐2) hits a small minority hard, while the vast majority of children appear to be protected and develop mild or no disease (1,2). The editorial by Brodin suggests some possible mechanisms why it is so (1). I would like to emphasize the significance of cross immunity due to previous exposure to seasonal coronavirus; it may be a plausible explanation for why children appear to be protected (2,3).\n",
            "Document 2: Title: Lessons for COVID-19 immunity from other coronavirus infections Text: Abstract A key goal to controlling COVID-19 is developing an effective vaccine. Development of a vaccine requires knowledge of what constitutes a protective immune response and also features that might be pathogenic. Protective and pathogenic aspects of the response to SARS-CoV-2 are not well understood, partly because the virus has infected humans for only 6 months. However, insight into coronavirus immunity can be informed by previous studies of immune responses to non-human coronaviruses, to common cold coronaviruses, and to SARS-CoV and MERS-CoV. Here we review the literature describing these responses and discuss their relevance to the SARS-CoV-2 immune response.\n",
            "Document 3: Title: A systematic review of antibody mediated immunity to coronaviruses: antibody kinetics, correlates of protection, and association of antibody responses with severity of disease Text: The duration and nature of immunity generated in response to SARS-CoV-2 infection is unknown. Many public health responses and modeled scenarios for COVID-19 outbreaks caused by SARSCoV-2 assume that infection results in an immune response that protects individuals from future infections or illness for some amount of time. The timescale of protection is a critical determinant of the future impact of the pathogen. The presence or absence of protective immunity due to infection or vaccination (when available) will affect future transmission and illness severity. The dynamics of immunity and nature of protection are relevant to discussions surrounding therapeutic use of convalescent sera as well as efforts to identify individuals with protective immunity. Here, we review the scientific literature on antibody immunity to coronaviruses, including SARS-CoV-2 as well as the related SARS-CoV-1, MERS-CoV and human endemic coronaviruses (HCoVs). We reviewed 1281 abstracts and identified 322 manuscripts relevant to 5 areas of focus: 1) antibody kinetics, 2) correlates of protection, 3) immunopathogenesis, 4) antigenic diversity and cross-reactivity, and 5) population seroprevalence. While studies of SARS-CoV-2 are necessary to determine immune responses to it, evidence from other coronaviruses can provide clues and guide future research.\n",
            "Document 4: Title: Could BCG Vaccination Induce Protective Trained Immunity for SARS-CoV-2? Text: Trained immunity is a type of non-specific memory-like immune response induced by some pathogens and vaccines, such as BCG, which can confer antigen-independent protection against a wide variety of pathogens. The BCG vaccine has been extensively used to protect against tuberculosis for almost a 100 years. Interestingly, this vaccine reduces children's mortality caused by infections unrelated to Mycobacterium tuberculosis infection, a phenomenon thought to be due to the induction of trained immunity. The SARS-CoV-2 pandemic has infected, as of April 22, 2020, 2,623,231 people globally, causing a major public health problem worldwide. Currently, no vaccine or treatment is available to control this pandemic. We analyzed the number of positive cases and deaths in different countries and correlated them with the inclusion of BCG vaccination at birth in their national vaccination programs. Interestingly, those countries where BCG vaccination is given at birth have shown a lower contagion rate and fewer COVID-19-related deaths, suggesting that this vaccine may induce trained immunity that could confer some protection for SARS-CoV-2.\n",
            "Document 5: Title: Could BCG Vaccination Induce Protective Trained Immunity for SARS-CoV-2? Text: Trained immunity is a type of non-specific memory-like immune response induced by some pathogens and vaccines, such as BCG, which can confer antigen-independent protection against a wide variety of pathogens. The BCG vaccine has been extensively used to protect against tuberculosis for almost a 100 years. Interestingly, this vaccine reduces children's mortality caused by infections unrelated to Mycobacterium tuberculosis infection, a phenomenon thought to be due to the induction of trained immunity. The SARS-CoV-2 pandemic has infected, as of April 22, 2020, 2,623,231 people globally, causing a major public health problem worldwide. Currently, no vaccine or treatment is available to control this pandemic. We analyzed the number of positive cases and deaths in different countries and correlated them with the inclusion of BCG vaccination at birth in their national vaccination programs. Interestingly, those countries where BCG vaccination is given at birth have shown a lower contagion rate and fewer COVID-19-related deaths, suggesting that this vaccine may induce trained immunity that could confer some protection for SARS-CoV-2.\n",
            "\n",
            "Question:\n",
            "Title: coronavirus immunity\n",
            "Description: will SARS-CoV2 infected people develop immunity? Is cross protection possible?\n",
            "Narrative: seeking studies of immunity developed due to infection with SARS-CoV2 or cross protection gained due to infection with other coronavirus types\n",
            "\n",
            "Answer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\n",
            "------------------ Response ------------------\n",
            "\"It is possible to gain immunity against COVID-19 by infection with other coronaviruses, including SARS-CoV and MERS-CoV.\" \"The data suggest that the immunity to SARS-CoV-2 is more durable than the immunity to other coronaviruses. Therefore, the data suggest that the immunity to SARS-CoV-2 is more durable than the immunity to other coronaviruses.\" \"Infection with SARS-CoV-2 may provide cross-protection against the related MERS-CoV and SARS-CoV, and against some other coronaviruses.\"\n"
          ]
        }
      ],
      "source": [
        "print(\"------------------ CASCADING RETRIEVAL ----------------------\\n\")\n",
        "context = \"\\n\".join(cascading_retrieved_docs)\n",
        "prompt = f\"Context:\\n{context}\\n\\nQuestion:\\n{query_text}\\n\\nAnswer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\"\n",
        "\n",
        "print(f\"----------------- Length of the prompt -----------------\\n{len(prompt.split())} words\")\n",
        "print(f\"------------------------ Prompt ------------------------\\n{prompt}\")\n",
        "\n",
        "# Generate response\n",
        "response = lm_pipeline(prompt,\n",
        "                      max_new_tokens=150,\n",
        "                      temperature=0.7,\n",
        "                      truncation=False)[0][\"generated_text\"]\n",
        "\n",
        "response = response.split(\"Answer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\")[1].strip()\n",
        "print(f\"------------------ Response ------------------\\n{response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8666f76",
      "metadata": {
        "id": "f8666f76"
      },
      "source": [
        "#### Question-answering WITH NO CONTEXT PROVIDED WITH RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d6793863-6d60-46c2-983a-2d8d44fa15aa",
      "metadata": {
        "id": "d6793863-6d60-46c2-983a-2d8d44fa15aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab4c6281-1a6e-4b9d-a812-62eac7f3f65f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------ RESPONSE WITHOUT RAG ----------------------\n",
            "\n",
            "----------------- Length of the prompt -----------------\n",
            "54 words\n",
            "------------------------ Prompt ------------------------\n",
            "Question:\n",
            "Title: coronavirus immunity\n",
            "Description: will SARS-CoV2 infected people develop immunity? Is cross protection possible?\n",
            "Narrative: seeking studies of immunity developed due to infection with SARS-CoV2 or cross protection gained due to infection with other coronavirus types\n",
            "\n",
            "Answer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\n",
            "------------------ Response ------------------\n",
            "yes, both SARS-CoV-2 and other coronaviruses cause severe acute respiratory syndrome, and the severity of the disease caused by SARS-CoV-2 is higher than that caused by other coronaviruses. The immunity is not cross-protection. Immunity to SARS-CoV-2 and other coronaviruses is acquired through infection with the respective virus. The severity of the disease caused by SARS-CoV-2 is higher than that caused by other coronaviruses. The immunity is not cross-protection.\n",
            "\n",
            "Explanation in a concise and clear manner without repetition (if no direct answer, provide a general summary): The coronavirus disease 2019 (COVID-19) caused by SARS-CoV-2 is a new\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"------------------ RESPONSE WITHOUT RAG ----------------------\\n\")\n",
        "prompt = f\"\"\"Question:\\n{query_text}\\n\\nAnswer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\"\"\"\n",
        "\n",
        "print(f\"----------------- Length of the prompt -----------------\\n{len(prompt.split())} words\")\n",
        "print(f\"------------------------ Prompt ------------------------\\n{prompt}\")\n",
        "\n",
        "response = lm_pipeline(prompt,\n",
        "                      max_new_tokens=150,\n",
        "                      temperature=0.7,\n",
        "                      truncation=False)[0][\"generated_text\"]\n",
        "\n",
        "response = response.split(\"Answer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\")[1].strip()\n",
        "print(f\"------------------ Response ------------------\\n{response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6c28e3f7",
      "metadata": {
        "id": "6c28e3f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "755bad3f-c595-4f41-e82d-fc4606441ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Title: Vitamin D and COVID-19\n",
            "Description: Does Vitamin D impact COVID-19 prevention and treatment?\n",
            "Narrative: This includes studies describing possible role of Vitamin D in prevention of COVID-19, suppression of cytokine storm, clinical outcomes, and associations between Vitamin D status and COVID-19 mortality.\n",
            "Cascading Response: Vitamin D supplementation is not effective in preventing COVID-19\n",
            "Description: Vitamin D supplementation is not effective in preventing COVID-19\n",
            "Narrative: This includes studies describing possible role of Vitamin D in prevention of COVID-19, suppression of cytokine storm, clinical outcomes, and associations between Vitamin D status and COVID-19 mortality.\n",
            "Rank Fusion Response: SARS-CoV2 infection is associated with a strong immune response, including antibodies against the virus. However, the duration of immunity is not known. Cross-protection against other coronaviruses has not been studied.\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Title: coronavirus quarantine\n",
            "Description: what are best practices in hospitals and at home in maintaining quarantine?\n",
            "Narrative: Seeking information on best practices for activities and duration of quarantine for those exposed and/ infected to COVID-19 virus.\n",
            "Cascading Response: Quarantine is a very effective method for containing the spread of highly infectious diseases in large populations during a pandemic, but it is only effective if properly implemented. The co-operation and compliance of people entering quarantine are critical to its success. However, owing to the isolating and social distancing nature of quarantine, it often leads to extreme economic hardship and shortages in basic needs such as food, medicine, water and communication- A nd to the curtailment of certain universal social norms such as attending a parent's funeral. To escape these hardships, people often refuse to enter voluntary quarantine, or breach quarantine rules. In these circumstances, health authorities are obliged to act in the best interests of the public and obtain court orders to force some people into quarantine. In further\n",
            "Rank Fusion Response: SARS-CoV2 infection is associated with a high risk of severe disease and death. However, the risk of severe disease and death is lower in people who have been infected with SARS-CoV2 than with other coronaviruses. This is likely due to the fact that SARS-CoV2 is a novel virus and has not been extensively studied. In addition, the immune response to SARS-CoV2 may be different from the immune response to other coronaviruses. Therefore, it is not clear whether SARS-CoV2 infection will confer long-term immunity. However, it is possible that some people may develop long-term immunity to SARS-CoV2 infection. Cross protection may be possible between SARS-CoV2 and other\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Title: coronavirus super spreaders\n",
            "Description: what evidence is there related to COVID-19 super spreaders\n",
            "Narrative: seeking range of information related to the number and proportion of super spreaders, their patterns of behavior that lead to spread, and potential prevention strategies targeted specifically toward super spreaders\n",
            "Cascading Response: The number of secondary cases from each primary case determines how fast an epidemic grows. It is known that all cases do not spread the infection equally; super spreaders play an important role as they contribute disproportionately to a much larger number of cases including in the ongoing COVID-19 pandemic. Super spreaders have been reported for more than a century, but limited information is available in scientific literature. An epidemic containment strategy needs to include early identification of super spreaders to limit an explosive growth. Super spreaders tend to get stigmatized, resulting in late reporting and hiding of cases. It is important for program managers to be sensitive to the manner in which related information is shared with media and general public.\n",
            "\n",
            "Answer in a concise and clear manner without repetition (if\n",
            "Rank Fusion Response: yes, SARS-CoV2 infected people develop immunity. No, cross protection is not possible.\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Title: coronavirus and ACE inhibitors\n",
            "Description: are patients taking Angiotensin-converting enzyme inhibitors (ACE) at increased risk for COVID-19?\n",
            "Narrative: Looking for information on interactions between  coronavirus and  angiotensin converting enzyme 2 (ACE2) receptors, risk for patients taking these medications, and recommendations for these patients.\n",
            "Cascading Response: There is no evidence of increased risk of coronavirus in patients taking ACE inhibitors or Ang II receptor blockers, but this is an observational study, so it's difficult to draw any conclusions. In summary, there is no evidence of increased risk of coronavirus in patients taking ACE inhibitors or Ang II receptor blockers, but this is an observational study, so it's difficult to draw any conclusions.\n",
            "Rank Fusion Response: SARS-CoV2 infection is associated with a high risk of severe disease and death. However, it is not clear whether SARS-CoV2 infection confers long-term immunity. Studies of immunity developed due to infection with SARS-CoV2 or cross protection gained due to infection with other coronavirus types are needed to better understand the long-term impact of SARS-CoV2 infection on the risk of severe disease and death.\n",
            "------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Query: Title: mRNA vaccine coronavirus\n",
            "Description: what is known about an mRNA vaccine for the SARS-CoV-2 virus?\n",
            "Narrative: Looking for studies specifically focusing on mRNA vaccines for COVID-19, including how mRNA vaccines work, why they are promising, and any results from actual clinical studies.\n",
            "Cascading Response: This review provides a comparison of the theoretical issues and experimental findings for plasmid DNA and mRNA vaccine technologies. While both have been under development since the 1990s, in recent years, significant excitement has turned to mRNA despite the licensure of several veterinary DNA vaccines. Both have required efforts to increase their potency either via manipulating the plasmid DNA and the mRNA directly or through the addition of adjuvants or immunomodulators as well as delivery systems and formulations. The greater inherent inflammatory nature of the mRNA vaccines is discussed for both its potential immunological utility for vaccines and for the potential toxicity. The status of the clinical trials of mRNA vaccines is described along with a comparison to DNA vaccines, specifically the immunogenicity of both licensed\n",
            "Rank Fusion Response: yes, SARS-CoV2 infected people develop immunity. No, cross protection is not possible.\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "picked_queries = random.sample(all_queries, 5)\n",
        "\n",
        "for q in picked_queries:\n",
        "\n",
        "    # For each query, retrieve and rank documents independently\n",
        "    query_text = q['title']\n",
        "    cascading_top_k_indices, cascading_top_k_scores = cascade_retrieve(query_embeddings[QUERY_INDEX], doc_embeddings, query_text)\n",
        "\n",
        "    # Use the top-k documents for that specific query\n",
        "    cascading_retrieved_docs = [f\"Document {i+1}: {all_docs[idx]['abstract']}\" for i, idx in enumerate(cascading_top_k_indices)]\n",
        "    cascading_context = \"\\n\".join(cascading_retrieved_docs)\n",
        "\n",
        "    # Repeat the process for rank fusion\n",
        "    rank_top_k_indices, rank_top_k_scores = fusion_retrieve(query_embeddings[QUERY_INDEX], doc_embeddings, query_text)\n",
        "    rank_retrieved_docs = [f\"Document {i+1}: {all_docs[idx]['abstract']}\" for i, idx in enumerate(rank_top_k_indices)]\n",
        "    rank_fusion_context = \"\\n\".join(rank_retrieved_docs)\n",
        "\n",
        "\n",
        "    cascading_prompt = f\"Context:\\n{cascading_context}\\n\\nQuestion:\\n{query_text}\\n\\nAnswer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\"\n",
        "    rank_fusion_prompt = f\"Context:\\n{rank_fusion_context}\\n\\nQuestion:\\n{query_text}\\n\\nAnswer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\"\n",
        "\n",
        "    # Generate response using language model\n",
        "    cascading_response = lm_pipeline(cascading_prompt,\n",
        "                           max_new_tokens=150,\n",
        "                           temperature=0.7,\n",
        "                           truncation=False)[0][\"generated_text\"]\n",
        "\n",
        "    rank_fusion_response = lm_pipeline(prompt,\n",
        "                      max_new_tokens=150,\n",
        "                      temperature=0.1,\n",
        "                      truncation=False)[0][\"generated_text\"]\n",
        "\n",
        "    # Extract the answer from the response\n",
        "    cascading_response = cascading_response.split(\"Answer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\")[1].strip()\n",
        "    rank_fusion_response = rank_fusion_response.split(\"Answer in a concise and clear manner without repetition (if no direct answer, provide a general summary):\")[1].strip()\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"\\nQuery: {query_text}\")\n",
        "    print(f\"Cascading Response: {cascading_response}\")\n",
        "    print(f\"Rank Fusion Response: {rank_fusion_response}\")\n",
        "    print(\"------------------------------\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "795893fec9a8437f85fe21970348f570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e2df898ff1b4916ad34a477494acc57",
              "IPY_MODEL_17a36ea0e3604088a6b34bf9c682da84",
              "IPY_MODEL_8fce874545f74d1a92944b43c002f772"
            ],
            "layout": "IPY_MODEL_d028f9d5cf6e494f87d908f4a311a310"
          }
        },
        "5e2df898ff1b4916ad34a477494acc57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34e9a434dfb14bd688e6cd34bebff2b4",
            "placeholder": "​",
            "style": "IPY_MODEL_b5695d43941d45db97f46544207a308c",
            "value": "Batches: 100%"
          }
        },
        "17a36ea0e3604088a6b34bf9c682da84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d08818359d485ca4b23ba039a1bce6",
            "max": 6016,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3ce81bc64a743b1a8bd9c0d683ffc60",
            "value": 6016
          }
        },
        "8fce874545f74d1a92944b43c002f772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04bd573ba02d4a2694bfc5afb84b0d23",
            "placeholder": "​",
            "style": "IPY_MODEL_114d9c23d7db4f34893ecce9e91da7ad",
            "value": " 6016/6016 [07:23&lt;00:00, 84.16it/s]"
          }
        },
        "d028f9d5cf6e494f87d908f4a311a310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e9a434dfb14bd688e6cd34bebff2b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5695d43941d45db97f46544207a308c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76d08818359d485ca4b23ba039a1bce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3ce81bc64a743b1a8bd9c0d683ffc60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04bd573ba02d4a2694bfc5afb84b0d23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "114d9c23d7db4f34893ecce9e91da7ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82f812cd482046afb4bac2bedb54943a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0da4a24e4df34bf99401efd1cf77620d",
              "IPY_MODEL_834c36e68479487591b4afc1a26fbb0f",
              "IPY_MODEL_c4c29a426c844995973cb9d795e7d6b4"
            ],
            "layout": "IPY_MODEL_97e27779d6c9448ba5917faa30d2a701"
          }
        },
        "0da4a24e4df34bf99401efd1cf77620d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_634c2b8dc25c4056a9f8aca21e1e36f4",
            "placeholder": "​",
            "style": "IPY_MODEL_9c873afc715e457994cb458faa1f8126",
            "value": "Batches: 100%"
          }
        },
        "834c36e68479487591b4afc1a26fbb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5552f12948944c858c8add42b071cf86",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da35bf0f955a49249194e4a1f9b5a4cf",
            "value": 2
          }
        },
        "c4c29a426c844995973cb9d795e7d6b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e847684fbae4d50ae492fd5f52b7884",
            "placeholder": "​",
            "style": "IPY_MODEL_50a251a4dd2642ec80d30e480ca6cf16",
            "value": " 2/2 [00:00&lt;00:00, 18.84it/s]"
          }
        },
        "97e27779d6c9448ba5917faa30d2a701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "634c2b8dc25c4056a9f8aca21e1e36f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c873afc715e457994cb458faa1f8126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5552f12948944c858c8add42b071cf86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da35bf0f955a49249194e4a1f9b5a4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e847684fbae4d50ae492fd5f52b7884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50a251a4dd2642ec80d30e480ca6cf16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}